{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Over-sampling for imbalance problem\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "#logestic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Desicion Tree Classifer\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# SVM Classifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/hadi/Documents/Professional_development/DS/INSIGHT/Project/Data/Data_pro')\n",
    "raw_data=pd.read_csv('Data_All_sorted_alpha_MVP_V7_2.csv')\n",
    "\n",
    "#raw_data.index = raw_data.Neighbourhood\n",
    "\n",
    "Y = pd.DataFrame(raw_data['Label'])\n",
    "\n",
    "# Features selections\n",
    "# options -: All fesstures:\n",
    "X = pd.DataFrame(raw_data[['Home price','Change in housing pricing','Low income population',\\\n",
    "                             'Change in low income pop','Total Area','Total Population',\\\n",
    "                             'Pop  25 - 34 years','Recent Immigrants','TTC Stops','Health Providers','Businesses',\\\n",
    "                             'Social Housing Units','Rent Bank Applicants']])\n",
    "\n",
    "# options -2: High correlation features\n",
    "# X = pd.DataFrame(raw_data[['Change in low income pop',\\\n",
    "#                          'Pop  25 - 34 years','Businesses',\\\n",
    "#                         'Social Housing Units']])\n",
    "\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, Y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "\n",
    "#Split Test Train Data\n",
    "#Method -1: None Stratified\n",
    "    #if original data:\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 44)\n",
    "\n",
    "    #if resampled data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, y_resampled, test_size = 0.15, random_state = 42)\n",
    "\n",
    "# #Method -2 : Stratified\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=.15, random_state=44) # split is to classify for stratify\n",
    "# for train_index, test_index in split.split(raw_data, raw_data[['Label']]):  # column to use to stratify\n",
    "#     X_train = X.loc[train_index]\n",
    "#     X_test = X.loc[test_index]\n",
    "#     Y_train = Y.loc[train_index]\n",
    "#     Y_test = Y.loc[test_index]\n",
    "\n",
    "# encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(Y_train)\n",
    "# encoded_Y_train = encoder.transform(Y_train)\n",
    "# # convert integers to dummy variables (i.e. one hot encoded)\n",
    "# dummy_Y_train = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "# encoder.fit(Y_test)\n",
    "# encoded_Y_test= encoder.transform(Y_test)\n",
    "# # convert integers to dummy variables (i.e. one hot encoded)\n",
    "# dummy_Y_test= np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "#Standardize the Data\n",
    "X_train = pd.DataFrame(StandardScaler().fit_transform(X_train)) \n",
    "X_test = pd.DataFrame(StandardScaler().fit_transform(X_test))\n",
    "print(len(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogesticRegression Modelling ------------------------------------\n",
    "\n",
    "# define model\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "#from sklearn.utils.validation import column_or_1d\n",
    "#dummy_Y_train = column_or_1d(Y_train, warn=True)\n",
    "\n",
    "#if original data be used:\n",
    "#logisticRegr.fit((X_train, Y_train.values.ravel())\n",
    "\n",
    "#if resampled data used: (output is np.array)\n",
    "logisticRegr.fit(X_train, Y_train)\n",
    "\n",
    "# # save the model to disk\n",
    "predictive_model_CL_LR = 'finalized_LR_model_CL.sav'\n",
    "pickle.dump(logisticRegr, open(predictive_model_CL_LR, 'wb'))    \n",
    "\n",
    "# Desicion Tree Modeling ------------------------------------------\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, Y_train) \n",
    "# # save the model to disk\n",
    "predictive_model_CL_DT = 'finalized_DT_model_CL.sav'\n",
    "pickle.dump(dtree_model, open(predictive_model_CL_DT, 'wb')) \n",
    "\n",
    "# SVM Modeling ---------------------------------------------------\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, Y_train) \n",
    "# # save the model to disk\n",
    "predictive_model_CL_SVM = 'finalized_SVM_model_CL.sav'\n",
    "pickle.dump(svm_model_linear, open(predictive_model_CL_SVM, 'wb')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the model from disk - LR\n",
    "loaded_model = pickle.load(open('finalized_LR_model_CL.sav', 'rb'))\n",
    "y_pred_LR= loaded_model.predict(X_test)\n",
    "print(\"Logestic Regression method accuracy:\"+str(accuracy_score(Y_test,y_pred_LR)))\n",
    "\n",
    "# load the model from disk - DT\n",
    "loaded_model = pickle.load(open('finalized_DT_model_CL.sav', 'rb'))\n",
    "y_pred_DT= loaded_model.predict(X_test)\n",
    "print(\"Decision Tree method accuracy:\"+str(accuracy_score(Y_test,y_pred_DT)))\n",
    "\n",
    "# load the model from disk - SVM\n",
    "loaded_model = pickle.load(open('finalized_SVM_model_CL.sav', 'rb'))\n",
    "y_pred_DT= loaded_model.predict(X_test)\n",
    "print(\"SVM method accuracy:\"+str(accuracy_score(Y_test,y_pred_DT)))\n",
    "\n",
    "\n",
    "# Same score can be calculated as following:\n",
    "# score = logisticRegr.score(X_test, Y_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#mat=confusion_matrix(Y_test,y_pred_LR)\n",
    "mat=confusion_matrix(Y_test,y_pred_DT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "#from sklearn import cross_validation\n",
    "scores=cross_validate.cross_val_score(model, X_train, Y_train.values.ravel(), cv=cross_validation.LeaveOneOut(1))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng=np.random.RandomState(0)\n",
    "colors=rng.rand(65)\n",
    "sizes=1000*rng.rand(65)\n",
    "plt.scatter(Y_test,y_pred_Gau, c=colors, s=sizes, alpha=0.5, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.savefig('testplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load prediction data \n",
    "Test_2016=pd.read_csv('/Users/hadi/Documents/Professional_development/DS/INSIGHT/Project/Data/Data_pro/Data_All_sorted_alpha_MVP_2016_V7_1.csv')\n",
    "Test_2016.index = Test_2016.Neighbourhood\n",
    "Y_2021 = pd.DataFrame(Test_2016['Label'])\n",
    "# Features selections\n",
    "#options -: All fesstures:\n",
    "X_2016 = pd.DataFrame(Test_2016[['Home price','Change in housing pricing','Low income population',\\\n",
    "                              'Change in low income pop','Total Area','Total Population',\\\n",
    "                              'Pop  25 - 34 years','Recent Immigrants','TTC Stops','Health Providers','Businesses',\\\n",
    "                              'Social Housing Units','Rent Bank Applicants']])\n",
    "\n",
    "# options -2: High correlation features\n",
    "# X_2016 = pd.DataFrame(Test_2016[['Change in low income pop',\\\n",
    "#                          'Pop  25 - 34 years','Businesses',\\\n",
    "#                         'Social Housing Units']])\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('finalized_Gau_model_CL.sav', 'rb'))\n",
    "Y_2021_Gau= loaded_model.predict(X_2016)\n",
    "print(Y_2021_Gau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
