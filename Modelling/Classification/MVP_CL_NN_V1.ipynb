{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# Over-sampling for imbalance problem\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/hadi/Documents/Professional_development/DS/INSIGHT/Project/Data/Data_pro')\n",
    "raw_data=pd.read_csv('Data_All_sorted_alpha_MVP_V7_2.csv')\n",
    "\n",
    "#raw_data.index = raw_data.Neighbourhood\n",
    "\n",
    "Y = pd.DataFrame(raw_data['Label'])\n",
    "\n",
    "# Features selections\n",
    "# options -: All fesstures:\n",
    "X = pd.DataFrame(raw_data[['Home price','Change in housing pricing','Low income population',\\\n",
    "                             'Change in low income pop','Total Area','Total Population',\\\n",
    "                             'Pop  25 - 34 years','Recent Immigrants','TTC Stops','Health Providers','Businesses',\\\n",
    "                             'Social Housing Units','Rent Bank Applicants']])\n",
    "\n",
    "# options -2: High correlation features\n",
    "# X = pd.DataFrame(raw_data[['Change in low income pop',\\\n",
    "#                          'Pop  25 - 34 years','Businesses',\\\n",
    "#                         'Social Housing Units']])\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, Y)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "#Split Test Train Data\n",
    "#Method -1: None Stratified\n",
    "    #if original data:\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 44)\n",
    "\n",
    "    #if resampled data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, y_resampled, test_size = 0.15, random_state = 44)\n",
    "\n",
    "\n",
    "\n",
    "# #Method -2 : Stratified\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=.20, random_state=44) # split is to classify for stratify\n",
    "# for train_index, test_index in split.split(raw_data, raw_data[['Label']]):  # column to use to stratify\n",
    "#     X_train = X.loc[train_index]\n",
    "#     X_test = X.loc[test_index]\n",
    "#     Y_train = Y.loc[train_index]\n",
    "#     Y_test = Y.loc[test_index]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_Y_train = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test= encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_Y_test= np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "#Standardize the Data\n",
    "# X_train = pd.DataFrame(StandardScaler().fit_transform(X_train)) \n",
    "# X_test = pd.DataFrame(StandardScaler().fit_transform(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Modelling \n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "# Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    predictive_Cl_model_NN = 'finalized_Cl_NNmodel.sav'\n",
    "    pickle.dump(model, open(predictive_Cl_model_NN, 'wb'))  \n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X_train, dummy_Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# # create model\n",
    "# model = Sequential()\n",
    "# #    model.add(Dropout (0.2))\n",
    "# model.add(Dense(10, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "# # Compile model\n",
    "# model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "# # save the model to disk\n",
    "# predictive_model_NN = 'finalized_NNmodel_CL.sav'\n",
    "# pickle.dump(model, open(predictive_model_NN, 'wb'))    \n",
    "\n",
    "\n",
    "\n",
    "# # fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "\n",
    "# model.fit(X_train, Y_train, epochs=5, batch_size=20)\n",
    "# loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=20)\n",
    "\n",
    "# classes = model.predict(X_test, Y_test, batch_size=20)\n",
    "\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# # Since the result was lower for original data the folloing is commented. \n",
    "# # evaluate model with standardized dataset\n",
    "# #numpy.random.seed(seed)\n",
    "# # seed = 7\n",
    "# # estimators = []\n",
    "# # estimators.append(('standardize', StandardScaler()))\n",
    "# # estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "# # pipeline = Pipeline(estimators)\n",
    "# # kfold = KFold(n_splits=5, random_state=seed)\n",
    "# # results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "# # print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('finalized_Cl_NNmodel.sav', 'rb'))\n",
    "y_pred_NN= loaded_model.predict(X_test)\n",
    "y_pred_train_NN=loaded_model.predict(X_train)\n",
    "\n",
    "print(y_pred_NN)\n",
    "print(Y_test)\n",
    "#print(\"NN method accuracy:\"+str(accuracy_score(dummy_Y_test,y_pred_NN)))\n",
    "\n",
    "\n",
    "\n",
    "Error = np.abs(dummy_Y_test - y_pred_NN)#/np.abs(Y_test)\n",
    "print(\"Error : in \"+str(np.mean(Error)))\n",
    "\n",
    "rr_TRAIN = metrics.r2_score(dummy_Y_train, y_pred_train_NN)\n",
    "rr_TRAIN = round(rr_TRAIN,2)\n",
    "print(\"R-Squared-TRAIN =\"+str(rr_TRAIN))\n",
    "\n",
    "rr_TEST = metrics.r2_score(dummy_Y_test, y_pred_NN)\n",
    "rr_TEST = round(rr_TEST,2)\n",
    "print(\"R-Squared-TEST =\"+str(rr_TEST))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
